<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>tinytroupe.experimentation.in_place_experiment_runner API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tinytroupe.experimentation.in_place_experiment_runner</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import IPython
from IPython.display import display, Javascript

from tinytroupe.experimentation import logger
from tinytroupe.experimentation.statistical_tests import StatisticalTester
from tinytroupe.utils import merge_dicts

class InPlaceExperimentRunner:
    &#34;&#34;&#34;
    This class allows the execution of &#34;in-place&#34; experiments. That is to say, it allows the user to run experiments on the current codebase without needing to create a separate script for each experiment. This is achieved by:
       - having an external configuration file that saves the overall state of the experiment.
       - having methods that clients can call to know what is the current experiment (e.g. treatment, control, etc.)
       - clients taking different actions based on the current active experiment.
    &#34;&#34;&#34;
    def __init__(self, config_file_path: str=&#34;experiment_config.json&#34;):
        self.config_file_path = config_file_path
        self.experiment_config = self._load_or_create_config(config_file_path)
        self._save_config()

    def add_experiment(self, experiment_name: str):
        &#34;&#34;&#34;
        Add a new experiment to the configuration file.

        Args:
            experiment_name (str): Name of the experiment to add.
        &#34;&#34;&#34;
        if experiment_name in self.experiment_config[&#34;experiments&#34;]:
            logger.info(f&#34;Experiment &#39;{experiment_name}&#39; already exists, nothihg to add.&#34;)
        else:
            self.experiment_config[&#34;experiments&#34;][experiment_name] = {}
            self._save_config()
    
    def activate_next_experiment(self):
        &#34;&#34;&#34;
        Activate the next experiment in the list.
        &#34;&#34;&#34;
        if not self.experiment_config[&#34;finished_all_experiments&#34;]:
            experiments = list(self.experiment_config[&#34;experiments&#34;].keys())
            if not experiments:
                raise ValueError(&#34;No experiments available to activate.&#34;)
            
            # Initialize finished_experiments if it doesn&#39;t exist
            if &#34;finished_experiments&#34; not in self.experiment_config:
                self.experiment_config[&#34;finished_experiments&#34;] = []
            
            current_experiment = self.experiment_config.get(&#34;active_experiment&#34;)
            if current_experiment:
                # Auto-finish current experiment if not already finished
                if current_experiment not in self.experiment_config[&#34;finished_experiments&#34;]:
                    self.experiment_config[&#34;finished_experiments&#34;].append(current_experiment)
                
                current_index = experiments.index(current_experiment)
                next_index = current_index + 1
                
                # Find the next unfinished experiment
                while next_index &lt; len(experiments):
                    next_experiment = experiments[next_index]
                    if next_experiment not in self.experiment_config[&#34;finished_experiments&#34;]:
                        self.experiment_config[&#34;active_experiment&#34;] = next_experiment
                        break
                    next_index += 1
                
                # If we didn&#39;t find an unfinished experiment, mark all as finished
                if next_index &gt;= len(experiments):
                    self.experiment_config[&#34;active_experiment&#34;] = None
                    self.experiment_config[&#34;finished_all_experiments&#34;] = True
            else:
                # Start with the first unfinished experiment
                for exp in experiments:
                    if exp not in self.experiment_config[&#34;finished_experiments&#34;]:
                        self.experiment_config[&#34;active_experiment&#34;] = exp
                        break
                else:
                    # If all experiments are finished
                    self.experiment_config[&#34;active_experiment&#34;] = None
                    self.experiment_config[&#34;finished_all_experiments&#34;] = True
            
            self._save_config()
        
        else:
            logger.info(&#34;All experiments have been finished. No more experiments to activate.&#34;)

    def fix_active_experiment(self, experiment_name: str):
        &#34;&#34;&#34;
        Fix the active experiment to a specific one.

        Args:
            experiment_name (str): Name of the experiment to fix.
        &#34;&#34;&#34;
        if experiment_name not in self.experiment_config[&#34;experiments&#34;]:
            raise ValueError(f&#34;Experiment &#39;{experiment_name}&#39; does not exist.&#34;)
        
        self.experiment_config[&#34;active_experiment&#34;] = experiment_name
        self.experiment_config[&#34;finished_all_experiments&#34;] = False
        self._save_config()

    def get_active_experiment(self):

        &#34;&#34;&#34;
        Get the currently active experiment.

        Returns:
            str: Name of the active experiment.
        &#34;&#34;&#34;
        return self.experiment_config.get(&#34;active_experiment&#34;)

    def get_unfinished_experiments(self):
        &#34;&#34;&#34;
        Get the list of experiment names that haven&#39;t been finished yet.

        Returns:
            list: List of experiment names that are not marked as finished.
        &#34;&#34;&#34;
        all_experiments = set(self.experiment_config[&#34;experiments&#34;].keys())
        finished_experiments = set(self.experiment_config.get(&#34;finished_experiments&#34;, []))
        return list(all_experiments - finished_experiments)

    def has_finished_all_experiments(self):
        &#34;&#34;&#34;
        Check if all experiments have been finished.

        Returns:
            bool: True if all experiments are finished, False otherwise.
        &#34;&#34;&#34;
        return self.experiment_config.get(&#34;finished_all_experiments&#34;, False)

    def add_experiment_results(self, results: dict, experiment_name:str=None, merge:bool=True):
        &#34;&#34;&#34;
        Add a result for a specific experiment.

        Args:
            results (dict): Results to add.
            experiment_name (str): Name of the experiment. If None, the active experiment will be used.
        &#34;&#34;&#34;
        if experiment_name is None:
            experiment_name = self.get_active_experiment()
            if experiment_name is None:
                raise ValueError(&#34;No active experiment exists to add results to.&#34;)
        
        if experiment_name not in self.experiment_config[&#34;experiments&#34;]:
            raise ValueError(f&#34;Experiment &#39;{experiment_name}&#39; does not exist.&#34;)
        
        if &#34;results&#34; not in self.experiment_config[&#34;experiments&#34;][experiment_name]:
            self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;] = {}
        
        if merge:
            self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;] = \
                merge_dicts(self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;], results, remove_duplicates=False)
        else:
            self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;].update(results)
        self._save_config()
    
    def get_experiment_results(self, experiment_name: str = None):
        &#34;&#34;&#34;
        Get the results of a specific experiment or all experiments if no name is provided.

        Args:
            experiment_name (str): Name of the experiment. If None, returns results for all experiments.

        Returns:
            dict or list: A dictionary of all experiment results if experiment_name is None, 
                          otherwise a list of results for the specified experiment.
        &#34;&#34;&#34;
        if experiment_name is None:
            return {name: data.get(&#34;results&#34;, []) for name, data in self.experiment_config[&#34;experiments&#34;].items()}
        
        if experiment_name not in self.experiment_config[&#34;experiments&#34;]:
            raise ValueError(f&#34;Experiment &#39;{experiment_name}&#39; does not exist.&#34;)
        
        return self.experiment_config[&#34;experiments&#34;][experiment_name].get(&#34;results&#34;, [])
    
    def run_statistical_tests(self, control_experiment_name: str):
        &#34;&#34;&#34;
        Run statistical tests on the results of experiments, comparing one selected as control to the others,
        which are considered treatments.
        
        Args:
            control_experiment_name (str): Name of the control experiment. All other experiments will be treated as treatments 
                and compared to this one.

        Returns:
            dict: Results of the statistical tests.
        &#34;&#34;&#34;
        if not self.experiment_config[&#34;experiments&#34;]:
            raise ValueError(&#34;No experiments available to run statistical tests.&#34;)
        
        # pop control from cloned list of experiment results
        experiment_results = self.experiment_config[&#34;experiments&#34;].copy()
        control_experiment_results = {control_experiment_name: experiment_results.pop(control_experiment_name, None)}

        tester = StatisticalTester(control_experiment_data=control_experiment_results, 
                                   treatments_experiment_data=experiment_results,
                                   results_key=&#34;results&#34;)
        
        results = tester.run_test()
        self.experiment_config[&#34;experiments&#34;][control_experiment_name][&#34;statistical_test_results_vs_others&#34;] = results
        self._save_config()
        
        return results
       
    def finish_active_experiment(self):
        &#34;&#34;&#34;
        Mark the current active experiment as finished without activating the next one.
        If this was the last unfinished experiment, mark all experiments as finished.
        
        Returns:
            bool: True if an experiment was marked as finished, False if no active experiment exists.
        &#34;&#34;&#34;
        current_experiment = self.get_active_experiment()
        if not current_experiment:
            logger.info(&#34;No active experiment to finish.&#34;)
            return False
        
        if &#34;finished_experiments&#34; not in self.experiment_config:
            self.experiment_config[&#34;finished_experiments&#34;] = []
            
        if current_experiment not in self.experiment_config[&#34;finished_experiments&#34;]:
            self.experiment_config[&#34;finished_experiments&#34;].append(current_experiment)
            self.experiment_config[&#34;active_experiment&#34;] = None
            logger.info(f&#34;Experiment &#39;{current_experiment}&#39; marked as finished.&#34;)
            
            # Check if all experiments are now finished
            all_experiments = set(self.experiment_config[&#34;experiments&#34;].keys())
            finished_experiments = set(self.experiment_config[&#34;finished_experiments&#34;])
            
            if all_experiments.issubset(finished_experiments):
                self.experiment_config[&#34;finished_all_experiments&#34;] = True
                logger.info(&#34;All experiments have been finished.&#34;)
            
            self._save_config()
            return True
        return False

    def _load_or_create_config(self, config_file_path: str):
        &#34;&#34;&#34;
        Load the configuration file if it exists, otherwise create a new one.

        Args:
            config_file_path (str): Path to the configuration file.

        Returns:
            dict: Loaded or newly created configuration.
        &#34;&#34;&#34;
        try:
            config = self._load_config(config_file_path)
            logger.warning(f&#34;Configuration file &#39;{config_file_path}&#39; exists and was loaded successfully. If you are trying to fully rerun the experiments, delete it first.&#34;)
            return config
        
        except FileNotFoundError:
            return self._create_default_config(config_file_path)

    def _create_default_config(self, config_file_path):
        &#34;&#34;&#34;
        Create a default configuration file.

        Returns:
            dict: Default configuration.
        &#34;&#34;&#34;
        default_config = {
            &#34;experiments&#34;: {},
            &#34;active_experiment&#34;: None,
            &#34;finished_all_experiments&#34;: False,
            &#34;finished_experiments&#34;: []
        }

        return default_config

    def _load_config(self, config_file_path: str):
        import json
        with open(config_file_path, &#39;r&#39;) as file:
            config = json.load(file)
        return config
    
    def _save_config(self):
        import json
        with open(self.config_file_path, &#39;w&#39;) as file:
            json.dump(self.experiment_config, file, indent=4)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner"><code class="flex name class">
<span>class <span class="ident">InPlaceExperimentRunner</span></span>
<span>(</span><span>config_file_path: str = 'experiment_config.json')</span>
</code></dt>
<dd>
<div class="desc"><p>This class allows the execution of "in-place" experiments. That is to say, it allows the user to run experiments on the current codebase without needing to create a separate script for each experiment. This is achieved by:
- having an external configuration file that saves the overall state of the experiment.
- having methods that clients can call to know what is the current experiment (e.g. treatment, control, etc.)
- clients taking different actions based on the current active experiment.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InPlaceExperimentRunner:
    &#34;&#34;&#34;
    This class allows the execution of &#34;in-place&#34; experiments. That is to say, it allows the user to run experiments on the current codebase without needing to create a separate script for each experiment. This is achieved by:
       - having an external configuration file that saves the overall state of the experiment.
       - having methods that clients can call to know what is the current experiment (e.g. treatment, control, etc.)
       - clients taking different actions based on the current active experiment.
    &#34;&#34;&#34;
    def __init__(self, config_file_path: str=&#34;experiment_config.json&#34;):
        self.config_file_path = config_file_path
        self.experiment_config = self._load_or_create_config(config_file_path)
        self._save_config()

    def add_experiment(self, experiment_name: str):
        &#34;&#34;&#34;
        Add a new experiment to the configuration file.

        Args:
            experiment_name (str): Name of the experiment to add.
        &#34;&#34;&#34;
        if experiment_name in self.experiment_config[&#34;experiments&#34;]:
            logger.info(f&#34;Experiment &#39;{experiment_name}&#39; already exists, nothihg to add.&#34;)
        else:
            self.experiment_config[&#34;experiments&#34;][experiment_name] = {}
            self._save_config()
    
    def activate_next_experiment(self):
        &#34;&#34;&#34;
        Activate the next experiment in the list.
        &#34;&#34;&#34;
        if not self.experiment_config[&#34;finished_all_experiments&#34;]:
            experiments = list(self.experiment_config[&#34;experiments&#34;].keys())
            if not experiments:
                raise ValueError(&#34;No experiments available to activate.&#34;)
            
            # Initialize finished_experiments if it doesn&#39;t exist
            if &#34;finished_experiments&#34; not in self.experiment_config:
                self.experiment_config[&#34;finished_experiments&#34;] = []
            
            current_experiment = self.experiment_config.get(&#34;active_experiment&#34;)
            if current_experiment:
                # Auto-finish current experiment if not already finished
                if current_experiment not in self.experiment_config[&#34;finished_experiments&#34;]:
                    self.experiment_config[&#34;finished_experiments&#34;].append(current_experiment)
                
                current_index = experiments.index(current_experiment)
                next_index = current_index + 1
                
                # Find the next unfinished experiment
                while next_index &lt; len(experiments):
                    next_experiment = experiments[next_index]
                    if next_experiment not in self.experiment_config[&#34;finished_experiments&#34;]:
                        self.experiment_config[&#34;active_experiment&#34;] = next_experiment
                        break
                    next_index += 1
                
                # If we didn&#39;t find an unfinished experiment, mark all as finished
                if next_index &gt;= len(experiments):
                    self.experiment_config[&#34;active_experiment&#34;] = None
                    self.experiment_config[&#34;finished_all_experiments&#34;] = True
            else:
                # Start with the first unfinished experiment
                for exp in experiments:
                    if exp not in self.experiment_config[&#34;finished_experiments&#34;]:
                        self.experiment_config[&#34;active_experiment&#34;] = exp
                        break
                else:
                    # If all experiments are finished
                    self.experiment_config[&#34;active_experiment&#34;] = None
                    self.experiment_config[&#34;finished_all_experiments&#34;] = True
            
            self._save_config()
        
        else:
            logger.info(&#34;All experiments have been finished. No more experiments to activate.&#34;)

    def fix_active_experiment(self, experiment_name: str):
        &#34;&#34;&#34;
        Fix the active experiment to a specific one.

        Args:
            experiment_name (str): Name of the experiment to fix.
        &#34;&#34;&#34;
        if experiment_name not in self.experiment_config[&#34;experiments&#34;]:
            raise ValueError(f&#34;Experiment &#39;{experiment_name}&#39; does not exist.&#34;)
        
        self.experiment_config[&#34;active_experiment&#34;] = experiment_name
        self.experiment_config[&#34;finished_all_experiments&#34;] = False
        self._save_config()

    def get_active_experiment(self):

        &#34;&#34;&#34;
        Get the currently active experiment.

        Returns:
            str: Name of the active experiment.
        &#34;&#34;&#34;
        return self.experiment_config.get(&#34;active_experiment&#34;)

    def get_unfinished_experiments(self):
        &#34;&#34;&#34;
        Get the list of experiment names that haven&#39;t been finished yet.

        Returns:
            list: List of experiment names that are not marked as finished.
        &#34;&#34;&#34;
        all_experiments = set(self.experiment_config[&#34;experiments&#34;].keys())
        finished_experiments = set(self.experiment_config.get(&#34;finished_experiments&#34;, []))
        return list(all_experiments - finished_experiments)

    def has_finished_all_experiments(self):
        &#34;&#34;&#34;
        Check if all experiments have been finished.

        Returns:
            bool: True if all experiments are finished, False otherwise.
        &#34;&#34;&#34;
        return self.experiment_config.get(&#34;finished_all_experiments&#34;, False)

    def add_experiment_results(self, results: dict, experiment_name:str=None, merge:bool=True):
        &#34;&#34;&#34;
        Add a result for a specific experiment.

        Args:
            results (dict): Results to add.
            experiment_name (str): Name of the experiment. If None, the active experiment will be used.
        &#34;&#34;&#34;
        if experiment_name is None:
            experiment_name = self.get_active_experiment()
            if experiment_name is None:
                raise ValueError(&#34;No active experiment exists to add results to.&#34;)
        
        if experiment_name not in self.experiment_config[&#34;experiments&#34;]:
            raise ValueError(f&#34;Experiment &#39;{experiment_name}&#39; does not exist.&#34;)
        
        if &#34;results&#34; not in self.experiment_config[&#34;experiments&#34;][experiment_name]:
            self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;] = {}
        
        if merge:
            self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;] = \
                merge_dicts(self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;], results, remove_duplicates=False)
        else:
            self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;].update(results)
        self._save_config()
    
    def get_experiment_results(self, experiment_name: str = None):
        &#34;&#34;&#34;
        Get the results of a specific experiment or all experiments if no name is provided.

        Args:
            experiment_name (str): Name of the experiment. If None, returns results for all experiments.

        Returns:
            dict or list: A dictionary of all experiment results if experiment_name is None, 
                          otherwise a list of results for the specified experiment.
        &#34;&#34;&#34;
        if experiment_name is None:
            return {name: data.get(&#34;results&#34;, []) for name, data in self.experiment_config[&#34;experiments&#34;].items()}
        
        if experiment_name not in self.experiment_config[&#34;experiments&#34;]:
            raise ValueError(f&#34;Experiment &#39;{experiment_name}&#39; does not exist.&#34;)
        
        return self.experiment_config[&#34;experiments&#34;][experiment_name].get(&#34;results&#34;, [])
    
    def run_statistical_tests(self, control_experiment_name: str):
        &#34;&#34;&#34;
        Run statistical tests on the results of experiments, comparing one selected as control to the others,
        which are considered treatments.
        
        Args:
            control_experiment_name (str): Name of the control experiment. All other experiments will be treated as treatments 
                and compared to this one.

        Returns:
            dict: Results of the statistical tests.
        &#34;&#34;&#34;
        if not self.experiment_config[&#34;experiments&#34;]:
            raise ValueError(&#34;No experiments available to run statistical tests.&#34;)
        
        # pop control from cloned list of experiment results
        experiment_results = self.experiment_config[&#34;experiments&#34;].copy()
        control_experiment_results = {control_experiment_name: experiment_results.pop(control_experiment_name, None)}

        tester = StatisticalTester(control_experiment_data=control_experiment_results, 
                                   treatments_experiment_data=experiment_results,
                                   results_key=&#34;results&#34;)
        
        results = tester.run_test()
        self.experiment_config[&#34;experiments&#34;][control_experiment_name][&#34;statistical_test_results_vs_others&#34;] = results
        self._save_config()
        
        return results
       
    def finish_active_experiment(self):
        &#34;&#34;&#34;
        Mark the current active experiment as finished without activating the next one.
        If this was the last unfinished experiment, mark all experiments as finished.
        
        Returns:
            bool: True if an experiment was marked as finished, False if no active experiment exists.
        &#34;&#34;&#34;
        current_experiment = self.get_active_experiment()
        if not current_experiment:
            logger.info(&#34;No active experiment to finish.&#34;)
            return False
        
        if &#34;finished_experiments&#34; not in self.experiment_config:
            self.experiment_config[&#34;finished_experiments&#34;] = []
            
        if current_experiment not in self.experiment_config[&#34;finished_experiments&#34;]:
            self.experiment_config[&#34;finished_experiments&#34;].append(current_experiment)
            self.experiment_config[&#34;active_experiment&#34;] = None
            logger.info(f&#34;Experiment &#39;{current_experiment}&#39; marked as finished.&#34;)
            
            # Check if all experiments are now finished
            all_experiments = set(self.experiment_config[&#34;experiments&#34;].keys())
            finished_experiments = set(self.experiment_config[&#34;finished_experiments&#34;])
            
            if all_experiments.issubset(finished_experiments):
                self.experiment_config[&#34;finished_all_experiments&#34;] = True
                logger.info(&#34;All experiments have been finished.&#34;)
            
            self._save_config()
            return True
        return False

    def _load_or_create_config(self, config_file_path: str):
        &#34;&#34;&#34;
        Load the configuration file if it exists, otherwise create a new one.

        Args:
            config_file_path (str): Path to the configuration file.

        Returns:
            dict: Loaded or newly created configuration.
        &#34;&#34;&#34;
        try:
            config = self._load_config(config_file_path)
            logger.warning(f&#34;Configuration file &#39;{config_file_path}&#39; exists and was loaded successfully. If you are trying to fully rerun the experiments, delete it first.&#34;)
            return config
        
        except FileNotFoundError:
            return self._create_default_config(config_file_path)

    def _create_default_config(self, config_file_path):
        &#34;&#34;&#34;
        Create a default configuration file.

        Returns:
            dict: Default configuration.
        &#34;&#34;&#34;
        default_config = {
            &#34;experiments&#34;: {},
            &#34;active_experiment&#34;: None,
            &#34;finished_all_experiments&#34;: False,
            &#34;finished_experiments&#34;: []
        }

        return default_config

    def _load_config(self, config_file_path: str):
        import json
        with open(config_file_path, &#39;r&#39;) as file:
            config = json.load(file)
        return config
    
    def _save_config(self):
        import json
        with open(self.config_file_path, &#39;w&#39;) as file:
            json.dump(self.experiment_config, file, indent=4)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.activate_next_experiment"><code class="name flex">
<span>def <span class="ident">activate_next_experiment</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Activate the next experiment in the list.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def activate_next_experiment(self):
    &#34;&#34;&#34;
    Activate the next experiment in the list.
    &#34;&#34;&#34;
    if not self.experiment_config[&#34;finished_all_experiments&#34;]:
        experiments = list(self.experiment_config[&#34;experiments&#34;].keys())
        if not experiments:
            raise ValueError(&#34;No experiments available to activate.&#34;)
        
        # Initialize finished_experiments if it doesn&#39;t exist
        if &#34;finished_experiments&#34; not in self.experiment_config:
            self.experiment_config[&#34;finished_experiments&#34;] = []
        
        current_experiment = self.experiment_config.get(&#34;active_experiment&#34;)
        if current_experiment:
            # Auto-finish current experiment if not already finished
            if current_experiment not in self.experiment_config[&#34;finished_experiments&#34;]:
                self.experiment_config[&#34;finished_experiments&#34;].append(current_experiment)
            
            current_index = experiments.index(current_experiment)
            next_index = current_index + 1
            
            # Find the next unfinished experiment
            while next_index &lt; len(experiments):
                next_experiment = experiments[next_index]
                if next_experiment not in self.experiment_config[&#34;finished_experiments&#34;]:
                    self.experiment_config[&#34;active_experiment&#34;] = next_experiment
                    break
                next_index += 1
            
            # If we didn&#39;t find an unfinished experiment, mark all as finished
            if next_index &gt;= len(experiments):
                self.experiment_config[&#34;active_experiment&#34;] = None
                self.experiment_config[&#34;finished_all_experiments&#34;] = True
        else:
            # Start with the first unfinished experiment
            for exp in experiments:
                if exp not in self.experiment_config[&#34;finished_experiments&#34;]:
                    self.experiment_config[&#34;active_experiment&#34;] = exp
                    break
            else:
                # If all experiments are finished
                self.experiment_config[&#34;active_experiment&#34;] = None
                self.experiment_config[&#34;finished_all_experiments&#34;] = True
        
        self._save_config()
    
    else:
        logger.info(&#34;All experiments have been finished. No more experiments to activate.&#34;)</code></pre>
</details>
</dd>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.add_experiment"><code class="name flex">
<span>def <span class="ident">add_experiment</span></span>(<span>self, experiment_name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a new experiment to the configuration file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the experiment to add.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_experiment(self, experiment_name: str):
    &#34;&#34;&#34;
    Add a new experiment to the configuration file.

    Args:
        experiment_name (str): Name of the experiment to add.
    &#34;&#34;&#34;
    if experiment_name in self.experiment_config[&#34;experiments&#34;]:
        logger.info(f&#34;Experiment &#39;{experiment_name}&#39; already exists, nothihg to add.&#34;)
    else:
        self.experiment_config[&#34;experiments&#34;][experiment_name] = {}
        self._save_config()</code></pre>
</details>
</dd>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.add_experiment_results"><code class="name flex">
<span>def <span class="ident">add_experiment_results</span></span>(<span>self, results: dict, experiment_name: str = None, merge: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a result for a specific experiment.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>results</code></strong> :&ensp;<code>dict</code></dt>
<dd>Results to add.</dd>
<dt><strong><code>experiment_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the experiment. If None, the active experiment will be used.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_experiment_results(self, results: dict, experiment_name:str=None, merge:bool=True):
    &#34;&#34;&#34;
    Add a result for a specific experiment.

    Args:
        results (dict): Results to add.
        experiment_name (str): Name of the experiment. If None, the active experiment will be used.
    &#34;&#34;&#34;
    if experiment_name is None:
        experiment_name = self.get_active_experiment()
        if experiment_name is None:
            raise ValueError(&#34;No active experiment exists to add results to.&#34;)
    
    if experiment_name not in self.experiment_config[&#34;experiments&#34;]:
        raise ValueError(f&#34;Experiment &#39;{experiment_name}&#39; does not exist.&#34;)
    
    if &#34;results&#34; not in self.experiment_config[&#34;experiments&#34;][experiment_name]:
        self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;] = {}
    
    if merge:
        self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;] = \
            merge_dicts(self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;], results, remove_duplicates=False)
    else:
        self.experiment_config[&#34;experiments&#34;][experiment_name][&#34;results&#34;].update(results)
    self._save_config()</code></pre>
</details>
</dd>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.finish_active_experiment"><code class="name flex">
<span>def <span class="ident">finish_active_experiment</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Mark the current active experiment as finished without activating the next one.
If this was the last unfinished experiment, mark all experiments as finished.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if an experiment was marked as finished, False if no active experiment exists.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def finish_active_experiment(self):
    &#34;&#34;&#34;
    Mark the current active experiment as finished without activating the next one.
    If this was the last unfinished experiment, mark all experiments as finished.
    
    Returns:
        bool: True if an experiment was marked as finished, False if no active experiment exists.
    &#34;&#34;&#34;
    current_experiment = self.get_active_experiment()
    if not current_experiment:
        logger.info(&#34;No active experiment to finish.&#34;)
        return False
    
    if &#34;finished_experiments&#34; not in self.experiment_config:
        self.experiment_config[&#34;finished_experiments&#34;] = []
        
    if current_experiment not in self.experiment_config[&#34;finished_experiments&#34;]:
        self.experiment_config[&#34;finished_experiments&#34;].append(current_experiment)
        self.experiment_config[&#34;active_experiment&#34;] = None
        logger.info(f&#34;Experiment &#39;{current_experiment}&#39; marked as finished.&#34;)
        
        # Check if all experiments are now finished
        all_experiments = set(self.experiment_config[&#34;experiments&#34;].keys())
        finished_experiments = set(self.experiment_config[&#34;finished_experiments&#34;])
        
        if all_experiments.issubset(finished_experiments):
            self.experiment_config[&#34;finished_all_experiments&#34;] = True
            logger.info(&#34;All experiments have been finished.&#34;)
        
        self._save_config()
        return True
    return False</code></pre>
</details>
</dd>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.fix_active_experiment"><code class="name flex">
<span>def <span class="ident">fix_active_experiment</span></span>(<span>self, experiment_name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Fix the active experiment to a specific one.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the experiment to fix.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fix_active_experiment(self, experiment_name: str):
    &#34;&#34;&#34;
    Fix the active experiment to a specific one.

    Args:
        experiment_name (str): Name of the experiment to fix.
    &#34;&#34;&#34;
    if experiment_name not in self.experiment_config[&#34;experiments&#34;]:
        raise ValueError(f&#34;Experiment &#39;{experiment_name}&#39; does not exist.&#34;)
    
    self.experiment_config[&#34;active_experiment&#34;] = experiment_name
    self.experiment_config[&#34;finished_all_experiments&#34;] = False
    self._save_config()</code></pre>
</details>
</dd>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.get_active_experiment"><code class="name flex">
<span>def <span class="ident">get_active_experiment</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the currently active experiment.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Name of the active experiment.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_active_experiment(self):

    &#34;&#34;&#34;
    Get the currently active experiment.

    Returns:
        str: Name of the active experiment.
    &#34;&#34;&#34;
    return self.experiment_config.get(&#34;active_experiment&#34;)</code></pre>
</details>
</dd>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.get_experiment_results"><code class="name flex">
<span>def <span class="ident">get_experiment_results</span></span>(<span>self, experiment_name: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the results of a specific experiment or all experiments if no name is provided.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>experiment_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the experiment. If None, returns results for all experiments.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code> or <code>list</code></dt>
<dd>A dictionary of all experiment results if experiment_name is None,
otherwise a list of results for the specified experiment.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_experiment_results(self, experiment_name: str = None):
    &#34;&#34;&#34;
    Get the results of a specific experiment or all experiments if no name is provided.

    Args:
        experiment_name (str): Name of the experiment. If None, returns results for all experiments.

    Returns:
        dict or list: A dictionary of all experiment results if experiment_name is None, 
                      otherwise a list of results for the specified experiment.
    &#34;&#34;&#34;
    if experiment_name is None:
        return {name: data.get(&#34;results&#34;, []) for name, data in self.experiment_config[&#34;experiments&#34;].items()}
    
    if experiment_name not in self.experiment_config[&#34;experiments&#34;]:
        raise ValueError(f&#34;Experiment &#39;{experiment_name}&#39; does not exist.&#34;)
    
    return self.experiment_config[&#34;experiments&#34;][experiment_name].get(&#34;results&#34;, [])</code></pre>
</details>
</dd>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.get_unfinished_experiments"><code class="name flex">
<span>def <span class="ident">get_unfinished_experiments</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the list of experiment names that haven't been finished yet.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>List of experiment names that are not marked as finished.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_unfinished_experiments(self):
    &#34;&#34;&#34;
    Get the list of experiment names that haven&#39;t been finished yet.

    Returns:
        list: List of experiment names that are not marked as finished.
    &#34;&#34;&#34;
    all_experiments = set(self.experiment_config[&#34;experiments&#34;].keys())
    finished_experiments = set(self.experiment_config.get(&#34;finished_experiments&#34;, []))
    return list(all_experiments - finished_experiments)</code></pre>
</details>
</dd>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.has_finished_all_experiments"><code class="name flex">
<span>def <span class="ident">has_finished_all_experiments</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Check if all experiments have been finished.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if all experiments are finished, False otherwise.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def has_finished_all_experiments(self):
    &#34;&#34;&#34;
    Check if all experiments have been finished.

    Returns:
        bool: True if all experiments are finished, False otherwise.
    &#34;&#34;&#34;
    return self.experiment_config.get(&#34;finished_all_experiments&#34;, False)</code></pre>
</details>
</dd>
<dt id="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.run_statistical_tests"><code class="name flex">
<span>def <span class="ident">run_statistical_tests</span></span>(<span>self, control_experiment_name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Run statistical tests on the results of experiments, comparing one selected as control to the others,
which are considered treatments.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>control_experiment_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the control experiment. All other experiments will be treated as treatments
and compared to this one.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Results of the statistical tests.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_statistical_tests(self, control_experiment_name: str):
    &#34;&#34;&#34;
    Run statistical tests on the results of experiments, comparing one selected as control to the others,
    which are considered treatments.
    
    Args:
        control_experiment_name (str): Name of the control experiment. All other experiments will be treated as treatments 
            and compared to this one.

    Returns:
        dict: Results of the statistical tests.
    &#34;&#34;&#34;
    if not self.experiment_config[&#34;experiments&#34;]:
        raise ValueError(&#34;No experiments available to run statistical tests.&#34;)
    
    # pop control from cloned list of experiment results
    experiment_results = self.experiment_config[&#34;experiments&#34;].copy()
    control_experiment_results = {control_experiment_name: experiment_results.pop(control_experiment_name, None)}

    tester = StatisticalTester(control_experiment_data=control_experiment_results, 
                               treatments_experiment_data=experiment_results,
                               results_key=&#34;results&#34;)
    
    results = tester.run_test()
    self.experiment_config[&#34;experiments&#34;][control_experiment_name][&#34;statistical_test_results_vs_others&#34;] = results
    self._save_config()
    
    return results</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tinytroupe.experimentation" href="index.html">tinytroupe.experimentation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner">InPlaceExperimentRunner</a></code></h4>
<ul class="">
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.activate_next_experiment" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.activate_next_experiment">activate_next_experiment</a></code></li>
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.add_experiment" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.add_experiment">add_experiment</a></code></li>
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.add_experiment_results" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.add_experiment_results">add_experiment_results</a></code></li>
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.finish_active_experiment" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.finish_active_experiment">finish_active_experiment</a></code></li>
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.fix_active_experiment" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.fix_active_experiment">fix_active_experiment</a></code></li>
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.get_active_experiment" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.get_active_experiment">get_active_experiment</a></code></li>
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.get_experiment_results" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.get_experiment_results">get_experiment_results</a></code></li>
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.get_unfinished_experiments" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.get_unfinished_experiments">get_unfinished_experiments</a></code></li>
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.has_finished_all_experiments" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.has_finished_all_experiments">has_finished_all_experiments</a></code></li>
<li><code><a title="tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.run_statistical_tests" href="#tinytroupe.experimentation.in_place_experiment_runner.InPlaceExperimentRunner.run_statistical_tests">run_statistical_tests</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>