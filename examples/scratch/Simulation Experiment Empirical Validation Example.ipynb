{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7388fcde",
   "metadata": {},
   "source": [
    "# Simulation Experiment Empirical Validation\n",
    "\n",
    "**The Problem**: You've built a TinyTroupe simulation, but how do you know if it accurately reflects real-world behavior?\n",
    "\n",
    "**The Solution**: This validation system compares your simulation results against empirical data to give you a confidence score.\n",
    "\n",
    "*Note: data here is fictitious and for demonstration purposes only.*\n",
    "\n",
    "## Real-World Example: E-commerce Checkout Optimization\n",
    "\n",
    "**Scenario**: Your company is considering a new premium checkout flow. You have real customer data from the current system and want to validate your TinyTroupe simulation predictions before making a $2M investment.\n",
    "\n",
    "**The Stakes**: If your simulation is wrong, you could lose customers and revenue. If it's right, you could increase conversions by 40%.\n",
    "\n",
    "Let's see how close your simulation gets to reality..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477d7c72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T20:20:05.012549Z",
     "iopub.status.busy": "2025-07-14T20:20:05.011552Z",
     "iopub.status.idle": "2025-07-14T20:20:06.837936Z",
     "shell.execute_reply": "2025-07-14T20:20:06.835530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!\n",
      "DISCLAIMER: TinyTroupe relies on Artificial Intelligence (AI) models to generate content. \n",
      "The AI models are not perfect and may produce inappropriate or inacurate results. \n",
      "For any serious or consequential use, please review the generated content before using it.\n",
      "!!!!\n",
      "\n",
      "Looking for default config on: c:\\Users\\pdasilva\\repos\\TinyTroupe\\examples\\..\\tinytroupe\\utils\\..\\config.ini\n",
      "Found custom config on: c:\\Users\\pdasilva\\repos\\TinyTroupe\\examples\\config.ini\n",
      "TinyTroupe version: 0.5.1\n",
      "Current date and time (local): 2025-07-15 23:29:09\n",
      "Current date and time (UTC):   2025-07-16 02:29:09\n",
      "\n",
      "=================================\n",
      "Current TinyTroupe configuration \n",
      "=================================\n",
      "[OpenAI]\n",
      "api_type = openai\n",
      "azure_api_version = 2024-08-01-preview\n",
      "model = gpt-4o-mini\n",
      "reasoning_model = o3-mini\n",
      "embedding_model = text-embedding-3-small\n",
      "max_tokens = 16000\n",
      "temperature = 1.7\n",
      "freq_penalty = 0.1\n",
      "presence_penalty = 0.1\n",
      "timeout = 480\n",
      "max_attempts = 5\n",
      "waiting_time = 0\n",
      "exponential_backoff_factor = 5\n",
      "reasoning_effort = high\n",
      "cache_api_calls = False\n",
      "cache_file_name = openai_api_cache.pickle\n",
      "max_content_display_length = 1024\n",
      "azure_embedding_model_api_version = 2023-05-15\n",
      "\n",
      "[Simulation]\n",
      "parallel_agent_generation = True\n",
      "parallel_agent_actions = True\n",
      "rai_harmful_content_prevention = True\n",
      "rai_copyright_infringement_prevention = True\n",
      "\n",
      "[Cognition]\n",
      "enable_memory_consolidation = True\n",
      "min_episode_length = 15\n",
      "max_episode_length = 50\n",
      "episodic_memory_fixed_prefix_length = 10\n",
      "episodic_memory_lookback_length = 20\n",
      "\n",
      "[ActionGenerator]\n",
      "max_attempts = 2\n",
      "enable_quality_checks = False\n",
      "enable_regeneration = True\n",
      "enable_direct_correction = False\n",
      "enable_quality_check_for_persona_adherence = True\n",
      "enable_quality_check_for_selfconsistency = False\n",
      "enable_quality_check_for_fluency = False\n",
      "enable_quality_check_for_suitability = False\n",
      "enable_quality_check_for_similarity = False\n",
      "continue_on_failure = True\n",
      "quality_threshold = 5\n",
      "\n",
      "[Logging]\n",
      "loglevel = ERROR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from tinytroupe.validation import SimulationExperimentEmpiricalValidator, SimulationExperimentDataset, validate_simulation_experiment_empirically\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa987b",
   "metadata": {},
   "source": [
    "## The Data: Real Customer Behavior vs. TinyTroupe Simulation\n",
    "\n",
    "**Real Data**: Customers tested the current checkout flow over 3 months  \n",
    "**Simulation**: TinyTroupe agents tested the proposed premium checkout flow  \n",
    "**Question**: Can we trust the simulation to predict real customer behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1b69da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T03:49:59.634632Z",
     "iopub.status.busy": "2025-07-14T03:49:59.633630Z",
     "iopub.status.idle": "2025-07-14T03:49:59.660147Z",
     "shell.execute_reply": "2025-07-14T03:49:59.658069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Real customer data loaded (3 months of actual e-commerce behavior)\n",
      "ü§ñ TinyTroupe simulation data loaded (premium checkout predictions)\n",
      "üí∞ Predicted revenue increase: 68% per visitor\n",
      "‚ö†Ô∏è  Question: Can we trust this simulation before investing $2M?\n"
     ]
    }
   ],
   "source": [
    "# REAL CUSTOMER DATA (3 months of actual e-commerce data)\n",
    "real_customer_data = {\n",
    "    \"name\": \"Real E-commerce Customer Data\",\n",
    "    \"description\": \"Actual customer behavior from current checkout system\",\n",
    "    \"key_results\": {\n",
    "        # Extended data with more sample points to avoid statistical issues\n",
    "        \"conversion_rate\": [0.23, 0.19, 0.25, 0.21, 0.24, 0.18, 0.22, 0.20, 0.26, 0.19, \n",
    "                           0.24, 0.22, 0.20, 0.25, 0.23, 0.21, 0.19, 0.24, 0.22, 0.20],  # 20 weekly averages\n",
    "        \"cart_abandonment_rate\": [0.68, 0.72, 0.65, 0.70, 0.67, 0.74, 0.69, 0.71, 0.64, 0.73,\n",
    "                                 0.69, 0.71, 0.68, 0.66, 0.72, 0.70, 0.67, 0.69, 0.71, 0.68],\n",
    "        \"average_order_value\": [87.50, 92.30, 85.20, 89.10, 91.80, 83.40, 88.90, 86.70, 94.20, 84.60,\n",
    "                               89.30, 91.50, 87.80, 90.20, 88.60, 86.40, 92.10, 89.70, 87.30, 90.80],\n",
    "        \"customer_satisfaction\": [3.2, 3.4, 3.1, 3.3, 3.5, 3.0, 3.2, 3.4, 3.6, 3.1,\n",
    "                                 3.3, 3.2, 3.4, 3.1, 3.3, 3.5, 3.0, 3.2, 3.4, 3.3],\n",
    "        \"overall_revenue_per_visitor\": 20.13  # Key business metric\n",
    "    },\n",
    "    \"result_types\": {\n",
    "        \"conversion_rate\": \"per_agent\",\n",
    "        \"cart_abandonment_rate\": \"per_agent\", \n",
    "        \"average_order_value\": \"per_agent\",\n",
    "        \"customer_satisfaction\": \"per_agent\",\n",
    "        \"overall_revenue_per_visitor\": \"aggregate\"\n",
    "    },\n",
    "    \"agent_justifications\": [\n",
    "        \"Too many steps in checkout - gave up halfway through\",\n",
    "        \"Payment options were confusing, wasn't sure which to choose\",\n",
    "        \"Completed purchase but the process felt unnecessarily complicated\",\n",
    "        \"Loading times were too slow, lost patience\",\n",
    "        \"Smooth experience overall, would buy again\"\n",
    "    ],\n",
    "    \"justification_summary\": \"Current checkout has friction points: too many steps, confusing payment options, slow loading times. Customers abandon due to complexity.\"\n",
    "}\n",
    "\n",
    "# TINYTROUPE SIMULATION DATA (proposed premium checkout with AI assistance)\n",
    "tinytroupe_simulation_data = {\n",
    "    \"name\": \"TinyTroupe Premium Checkout Simulation\",\n",
    "    \"description\": \"Simulation of new premium checkout with AI assistant and streamlined flow\",\n",
    "    \"key_results\": {\n",
    "        # Extended data with more sample points to match real data\n",
    "        \"conversion_rate\": [0.34, 0.31, 0.36, 0.33, 0.35, 0.29, 0.32, 0.30, 0.37, 0.31,\n",
    "                           0.33, 0.35, 0.32, 0.34, 0.36, 0.30, 0.33, 0.35, 0.31, 0.34],  # Predicted higher conversion\n",
    "        \"cart_abandonment_rate\": [0.45, 0.48, 0.42, 0.46, 0.44, 0.50, 0.43, 0.47, 0.41, 0.49,\n",
    "                                 0.44, 0.46, 0.43, 0.45, 0.47, 0.42, 0.48, 0.44, 0.46, 0.45],  # Predicted lower abandonment\n",
    "        \"average_order_value\": [102.30, 108.50, 99.80, 105.20, 110.40, 97.60, 104.10, 101.90, 112.30, 98.70,\n",
    "                               105.80, 103.40, 107.20, 101.60, 109.30, 104.70, 106.50, 102.80, 108.90, 105.10],  # Higher AOV\n",
    "        \"customer_satisfaction\": [4.1, 4.3, 3.9, 4.2, 4.4, 3.8, 4.0, 4.2, 4.5, 3.9,\n",
    "                                 4.2, 4.1, 4.3, 4.0, 4.4, 3.9, 4.1, 4.3, 4.2, 4.0],  # Higher satisfaction\n",
    "        \"overall_revenue_per_visitor\": 33.85  # 68% increase predicted!\n",
    "    },\n",
    "    \"result_types\": {\n",
    "        \"conversion_rate\": \"per_agent\",\n",
    "        \"cart_abandonment_rate\": \"per_agent\",\n",
    "        \"average_order_value\": \"per_agent\", \n",
    "        \"customer_satisfaction\": \"per_agent\",\n",
    "        \"overall_revenue_per_visitor\": \"aggregate\"\n",
    "    },\n",
    "    \"agent_justifications\": [\n",
    "        \"AI assistant helped me find exactly what I needed quickly\",\n",
    "        \"One-click checkout made the process effortless\",\n",
    "        \"Smart recommendations increased my order value naturally\",\n",
    "        \"Felt confident about my purchase with the AI guidance\",\n",
    "        \"Fastest checkout experience I've ever had\"\n",
    "    ],\n",
    "    \"justification_summary\": \"Premium checkout eliminates friction with AI assistance, one-click payment, and smart recommendations. Customers feel guided and confident.\"\n",
    "}\n",
    "\n",
    "print(\"üìä Real customer data loaded (3 months of actual e-commerce behavior)\")\n",
    "print(\"ü§ñ TinyTroupe simulation data loaded (premium checkout predictions)\")\n",
    "print(\"üí∞ Predicted revenue increase: 68% per visitor\")\n",
    "print(\"‚ö†Ô∏è  Question: Can we trust this simulation before investing $2M?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a337453",
   "metadata": {},
   "source": [
    "## The Validation: Can We Trust the Simulation?\n",
    "\n",
    "The system compares your simulation against real data using:\n",
    "- **Statistical tests** - Are the differences significant?\n",
    "- **Semantic analysis** - Do the reasons make sense?\n",
    "- **Confidence score** - How much can we trust this simulation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824d384a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T03:49:59.666379Z",
     "iopub.status.busy": "2025-07-14T03:49:59.666379Z",
     "iopub.status.idle": "2025-07-14T03:50:42.069708Z",
     "shell.execute_reply": "2025-07-14T03:50:42.064708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ VALIDATION RESULTS\n",
      "==================================================\n",
      "üìä Confidence Score: 33.2%\n",
      "üìà Simulation Quality: Statistical validation: 4/5 tests significant, average effect size: 4.739; Semantic validation: Average proximity score of 0.282; Summary proximity: 0.400; Overall validation score: 0.332\n",
      "‚ùå LOW CONFIDENCE - Simulation may not be reliable\n"
     ]
    }
   ],
   "source": [
    "# Run the validation - this is where the magic happens!\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "# Suppress statistical warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "try:\n",
    "    validation_result = validate_simulation_experiment_empirically(\n",
    "        control_data=real_customer_data,\n",
    "        treatment_data=tinytroupe_simulation_data,\n",
    "        validation_types=[\"statistical\", \"semantic\"],\n",
    "        significance_level=0.05,\n",
    "        output_format=\"values\"\n",
    "    )\n",
    "    \n",
    "    print(\"üéØ VALIDATION RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if validation_result.overall_score is not None:\n",
    "        print(f\"üìä Confidence Score: {validation_result.overall_score:.1%}\")\n",
    "        print(f\"üìà Simulation Quality: {validation_result.summary}\")\n",
    "        \n",
    "        # Quick interpretation\n",
    "        if validation_result.overall_score > 0.8:\n",
    "            print(\"‚úÖ HIGH CONFIDENCE - Simulation is very reliable\")\n",
    "        elif validation_result.overall_score > 0.6:\n",
    "            print(\"‚ö†Ô∏è  MEDIUM CONFIDENCE - Simulation has some reliability\")\n",
    "        else:\n",
    "            print(\"‚ùå LOW CONFIDENCE - Simulation may not be reliable\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Validation completed but confidence score could not be calculated\")\n",
    "        print(f\"üìà Summary: {validation_result.summary}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"‚ùå VALIDATION ERROR\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Error during validation: {str(e)}\")\n",
    "    print(\"üí° This might be due to insufficient data or statistical computation issues.\")\n",
    "    print(\"   Consider using more data points or different validation methods.\")\n",
    "    \n",
    "    # Create a fallback basic comparison\n",
    "    print(\"\\nüìä FALLBACK: Basic Data Comparison\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Simple mean comparisons\n",
    "    real_conv = np.mean(real_customer_data['key_results']['conversion_rate'])\n",
    "    sim_conv = np.mean(tinytroupe_simulation_data['key_results']['conversion_rate'])\n",
    "    \n",
    "    print(f\"Real conversion rate: {real_conv:.1%}\")\n",
    "    print(f\"Simulated conversion rate: {sim_conv:.1%}\")\n",
    "    print(f\"Predicted improvement: {((sim_conv - real_conv) / real_conv) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c287a55e",
   "metadata": {},
   "source": [
    "## Deep Dive: What the Numbers Tell Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35224dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T03:50:42.083710Z",
     "iopub.status.busy": "2025-07-14T03:50:42.082712Z",
     "iopub.status.idle": "2025-07-14T03:50:42.114524Z",
     "shell.execute_reply": "2025-07-14T03:50:42.110406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä STATISTICAL ANALYSIS\n",
      "========================================\n",
      "üìà Metrics analyzed: customer_satisfaction, cart_abandonment_rate, conversion_rate, overall_revenue_per_visitor, average_order_value\n",
      "üìä Statistical analysis encountered an issue:\n",
      "   'str' object has no attribute 'get'\n",
      "   This might be due to insufficient data for statistical testing.\n"
     ]
    }
   ],
   "source": [
    "# Examine the statistical evidence\n",
    "try:\n",
    "    if validation_result.statistical_results:\n",
    "        print(\"üìä STATISTICAL ANALYSIS\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        if \"error\" in validation_result.statistical_results:\n",
    "            print(f\"‚ùå Error: {validation_result.statistical_results['error']}\")\n",
    "        else:\n",
    "            metrics = validation_result.statistical_results['common_metrics']\n",
    "            print(f\"üìà Metrics analyzed: {', '.join(metrics)}\")\n",
    "            \n",
    "            # Show key findings\n",
    "            test_results = validation_result.statistical_results['test_results']\n",
    "            significant_differences = []\n",
    "            \n",
    "            for treatment_name, treatment_results in test_results.items():\n",
    "                for metric, metric_results in treatment_results.items():\n",
    "                    for test_name, test_result in metric_results.items():\n",
    "                        if test_result.get('significant', False):\n",
    "                            p_val = test_result.get('p_value', 'N/A')\n",
    "                            if isinstance(p_val, (int, float)) and not np.isnan(p_val):\n",
    "                                significant_differences.append(f\"{metric}: p={p_val:.3f}\")\n",
    "                            else:\n",
    "                                significant_differences.append(f\"{metric}: significant\")\n",
    "            \n",
    "            if significant_differences:\n",
    "                print(\"‚ö†Ô∏è  Significant differences found:\")\n",
    "                for diff in significant_differences:\n",
    "                    print(f\"   ‚Ä¢ {diff}\")\n",
    "            else:\n",
    "                print(\"‚úÖ No significant differences - simulation aligns with real data\")\n",
    "    else:\n",
    "        print(\"üìä No statistical results available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"üìä Statistical analysis encountered an issue:\")\n",
    "    print(f\"   {str(e)}\")\n",
    "    print(\"   This might be due to insufficient data for statistical testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e633ae81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T03:50:42.128165Z",
     "iopub.status.busy": "2025-07-14T03:50:42.127152Z",
     "iopub.status.idle": "2025-07-14T03:50:42.157944Z",
     "shell.execute_reply": "2025-07-14T03:50:42.155909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† REASONING ANALYSIS\n",
      "========================================\n",
      "üéØ Reasoning alignment: 28.2%\n",
      "‚ùå Agent reasoning differs significantly from real customers\n",
      "\n",
      "üìù Summary comparison: 40.0% similar\n",
      "üí° Key insight: The two texts discuss the concept of checkout processes but from opposing perspectives. The first text highlights the is...\n"
     ]
    }
   ],
   "source": [
    "# Examine the reasoning alignment\n",
    "try:\n",
    "    if validation_result.semantic_results:\n",
    "        print(\"\\nüß† REASONING ANALYSIS\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        avg_proximity = validation_result.semantic_results.get('average_proximity')\n",
    "        if avg_proximity and not np.isnan(avg_proximity):\n",
    "            print(f\"üéØ Reasoning alignment: {avg_proximity:.1%}\")\n",
    "            \n",
    "            if avg_proximity > 0.7:\n",
    "                print(\"‚úÖ Agent reasoning closely matches real customer thinking\")\n",
    "            elif avg_proximity > 0.5:\n",
    "                print(\"‚ö†Ô∏è  Agent reasoning somewhat matches real customer thinking\")\n",
    "            else:\n",
    "                print(\"‚ùå Agent reasoning differs significantly from real customers\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Could not calculate reasoning alignment score\")\n",
    "        \n",
    "        # Show reasoning comparison\n",
    "        summary_comp = validation_result.semantic_results.get('summary_comparison')\n",
    "        if summary_comp and summary_comp.get('proximity_score') and not np.isnan(summary_comp.get('proximity_score', 0)):\n",
    "            print(f\"\\nüìù Summary comparison: {summary_comp['proximity_score']:.1%} similar\")\n",
    "            justification = summary_comp.get('justification', '')\n",
    "            if justification:\n",
    "                print(f\"üí° Key insight: {justification[:120]}...\")\n",
    "        else:\n",
    "            print(\"\\nüìù Summary comparison: Unable to calculate similarity\")\n",
    "    else:\n",
    "        print(\"\\nüß† No semantic analysis results available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"\\nüß† Semantic analysis encountered an issue:\")\n",
    "    print(f\"   {str(e)}\")\n",
    "    print(\"   This might be due to missing justification data or semantic processing issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf5e1d",
   "metadata": {},
   "source": [
    "## Business Impact Assessment\n",
    "\n",
    "Based on the validation results, here's what this means for your $2M investment decision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "085eb64a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T03:50:42.169977Z",
     "iopub.status.busy": "2025-07-14T03:50:42.168983Z",
     "iopub.status.idle": "2025-07-14T03:51:19.615149Z",
     "shell.execute_reply": "2025-07-14T03:51:19.614243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíº BUSINESS IMPACT ASSESSMENT\n",
      "==================================================\n",
      "üéØ Simulation Confidence: 33.2%\n",
      "‚ö†Ô∏è  Risk Level: HIGH\n",
      "üìä Risk-Adjusted Revenue Increase: 20.4%\n",
      "üí∞ Expected Monthly Revenue Gain: $204,000\n",
      "üìà Expected Annual Revenue Gain: $2,448,000\n",
      "üéØ Investment Payback Period: 9.8 months\n",
      "\n",
      "üèÜ RECOMMENDATION: CONSIDER more validation\n"
     ]
    }
   ],
   "source": [
    "# Calculate business impact based on validation confidence\n",
    "try:\n",
    "    confidence_score = validation_result.overall_score if validation_result.overall_score is not None else 0.5\n",
    "    predicted_revenue_increase = 0.68  # 68% increase from simulation\n",
    "    current_monthly_revenue = 1000000  # $1M per month\n",
    "\n",
    "    print(\"üíº BUSINESS IMPACT ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Risk-adjusted projections\n",
    "    if confidence_score > 0.8:\n",
    "        risk_adjustment = 0.9  # High confidence = 90% of predicted benefit\n",
    "        recommendation = \"PROCEED with investment\"\n",
    "        risk_level = \"LOW\"\n",
    "    elif confidence_score > 0.6:\n",
    "        risk_adjustment = 0.6  # Medium confidence = 60% of predicted benefit\n",
    "        recommendation = \"PROCEED with caution\"\n",
    "        risk_level = \"MEDIUM\"\n",
    "    else:\n",
    "        risk_adjustment = 0.3  # Low confidence = 30% of predicted benefit\n",
    "        recommendation = \"CONSIDER more validation\"\n",
    "        risk_level = \"HIGH\"\n",
    "\n",
    "    expected_revenue_increase = predicted_revenue_increase * risk_adjustment\n",
    "    monthly_revenue_gain = current_monthly_revenue * expected_revenue_increase\n",
    "    annual_revenue_gain = monthly_revenue_gain * 12\n",
    "\n",
    "    print(f\"üéØ Simulation Confidence: {confidence_score:.1%}\")\n",
    "    print(f\"‚ö†Ô∏è  Risk Level: {risk_level}\")\n",
    "    print(f\"üìä Risk-Adjusted Revenue Increase: {expected_revenue_increase:.1%}\")\n",
    "    print(f\"üí∞ Expected Monthly Revenue Gain: ${monthly_revenue_gain:,.0f}\")\n",
    "    print(f\"üìà Expected Annual Revenue Gain: ${annual_revenue_gain:,.0f}\")\n",
    "    \n",
    "    if monthly_revenue_gain > 0:\n",
    "        print(f\"üéØ Investment Payback Period: {2000000 / monthly_revenue_gain:.1f} months\")\n",
    "    else:\n",
    "        print(\"üéØ Investment Payback Period: Cannot calculate (no expected gain)\")\n",
    "        \n",
    "    print(f\"\\nüèÜ RECOMMENDATION: {recommendation}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"üíº BUSINESS IMPACT ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"‚ùå Error calculating business impact: {str(e)}\")\n",
    "    print(\"üí° Using basic assessment based on available data...\")\n",
    "    \n",
    "    # Basic fallback assessment\n",
    "    print(f\"üéØ Predicted Revenue Increase: 68%\")\n",
    "    print(f\"üí∞ Investment Amount: $2M\")\n",
    "    print(f\"‚ö†Ô∏è  Recommendation: Proceed with caution due to validation issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d36aa",
   "metadata": {},
   "source": [
    "## Quick Example: Statistics-Only Validation\n",
    "\n",
    "For simpler cases where you only have metrics (no customer reasoning), you can run statistical validation only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789e5b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Quick validation score: 16.6%\n",
      "üìä Results: Statistical validation: 2/2 tests significant, average effect size: 5.170; Overall validation score: 0.166\n"
     ]
    }
   ],
   "source": [
    "# Simple metrics-only validation\n",
    "simple_real_data = {\n",
    "    \"name\": \"Real Data - Metrics Only\",\n",
    "    \"key_results\": {\n",
    "        # Extended data for more robust statistical testing\n",
    "        \"click_through_rate\": [0.12, 0.15, 0.13, 0.14, 0.11, 0.16, 0.13, 0.12, 0.15, 0.14, \n",
    "                              0.13, 0.15, 0.12, 0.14, 0.16, 0.13, 0.12, 0.15, 0.14, 0.13],\n",
    "        \"time_on_page\": [45, 52, 48, 50, 46, 54, 47, 49, 51, 48, \n",
    "                        46, 53, 49, 47, 52, 50, 48, 51, 49, 47]  # seconds\n",
    "    },\n",
    "    \"result_types\": {\n",
    "        \"click_through_rate\": \"per_agent\",\n",
    "        \"time_on_page\": \"per_agent\"\n",
    "    }\n",
    "}\n",
    "\n",
    "simple_simulation_data = {\n",
    "    \"name\": \"Simulation - Metrics Only\", \n",
    "    \"key_results\": {\n",
    "        \"click_through_rate\": [0.18, 0.21, 0.19, 0.20, 0.17, 0.22, 0.19, 0.18, 0.21, 0.20,\n",
    "                              0.19, 0.21, 0.18, 0.20, 0.22, 0.19, 0.18, 0.21, 0.20, 0.19],\n",
    "        \"time_on_page\": [62, 68, 65, 64, 61, 70, 63, 66, 67, 64,\n",
    "                        61, 69, 65, 63, 68, 66, 62, 67, 64, 63]  # seconds\n",
    "    },\n",
    "    \"result_types\": {\n",
    "        \"click_through_rate\": \"per_agent\",\n",
    "        \"time_on_page\": \"per_agent\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Quick statistical validation with error handling\n",
    "try:\n",
    "    quick_result = validate_simulation_experiment_empirically(\n",
    "        control_data=simple_real_data,\n",
    "        treatment_data=simple_simulation_data,\n",
    "        validation_types=[\"statistical\"],\n",
    "        output_format=\"values\"\n",
    "    )\n",
    "    \n",
    "    if quick_result.overall_score is not None:\n",
    "        print(f\"‚ö° Quick validation score: {quick_result.overall_score:.1%}\")\n",
    "        print(f\"üìä Results: {quick_result.summary}\")\n",
    "    else:\n",
    "        print(\"‚ö° Quick validation completed with issues\")\n",
    "        print(f\"üìä Results: {quick_result.summary}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö° Quick validation error: {str(e)}\")\n",
    "    print(\"üìä Fallback: Basic comparison shows simulation predicts ~50% improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b10c7",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "This validation system gives you confidence in your TinyTroupe simulations by:\n",
    "\n",
    "1. **üìä Statistical Validation** - Tests if your simulation results are statistically similar to real-world data\n",
    "2. **üß† Semantic Validation** - Compares agent reasoning with real customer thinking patterns  \n",
    "3. **üéØ Confidence Scoring** - Provides a clear 0-100% confidence score for business decisions\n",
    "4. **üí∞ Risk Assessment** - Helps you make informed investment decisions based on validation confidence\n",
    "\n",
    "**The Bottom Line**: Before making expensive business decisions based on simulations, validate them against real data. This system tells you exactly how much you can trust your TinyTroupe predictions.\n",
    "\n",
    "### Next Steps\n",
    "- Collect real customer data for your use case\n",
    "- Run your TinyTroupe simulation  \n",
    "- Use this validation system to assess confidence\n",
    "- Make data-driven business decisions\n",
    "\n",
    "**Remember**: A simulation is only as good as its validation against reality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
